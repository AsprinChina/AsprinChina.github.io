<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[优化基础理论]]></title>
    <url>%2F2019%2F07%2F07%2Foptimizationbase%2F</url>
    <content type="text"><![CDATA[引言​ 小站里面后续很多内容都是围绕着优化展开的，所以第一篇博客自然就要讲一讲优化的基础内容。有两方面目的，一是介绍一些数学基础，省去后续赘述；二是规定一下标准形式，这会影响到后续一些结论的形式，本站均采用Boyd的《Convex Optimization》中的标准形式。 ​ 一般地，一个优化问题可以写为目标函数+约束（进一步区分为等式约束与不等式约束）的格式，本站中规定其标准形式为： \begin{split} &min\ \ &f(x)\\ &s.t. &g(x)\ge0\\ &&h(x)=0 \end{split}​ 再规定上述优化问题的拉格朗日函数为 L(x,\mu,\lambda)=f(x)+\mu ^T g(x)+\lambda ^T h(x)​ 上述形式和一些优化教材中的并不一致，比如陈宝林老师的《最优化》，其乘子定义是上述形式的相反数。之所以在各种形式中选取Boyd书中的这一种，是因为大多数文献中均采用这一格式，且诸多优化求解器如cplex、gurobi中的乘子定义也采用这一格式。 基本概念 梯度，雅可比矩阵，与海森矩阵 ​ 定义向量$x=[x_1,\ x_2,\ \cdots,\ x_n]^T$，标量函数$f(x)$，与向量函数$F(x)=[f_1(x),\ f_2(x),\ \cdots,\ f_m(x)]^T$ 则$f(x)$的梯度定义为 \nabla f(x)=[\frac{\partial f(x)}{\partial x_1},\ \frac{\partial f(x)}{\partial x_2}, \ \cdots,\ \frac{\partial f(x)}{\partial x_n}]^T$f(x)$的海森矩阵定义为 \nabla ^2 f(x) = \begin{bmatrix} \frac{\partial ^2 f(x)}{\partial x_1^2} & \frac{\partial ^2 f(x)}{\partial x_1 \partial x_2} & \cdots & \frac{\partial ^2 f(x)}{\partial x_1 \partial x_n} \\ \frac{\partial ^2 f(x)}{\partial x_2 \partial x_1} & \frac{\partial ^2 f(x)}{\partial x_2 ^2} & \cdots & \frac{\partial ^2 f(x)}{\partial x_2 \partial x_n} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial ^2 f(x)}{\partial x_n \partial x_1} & \frac{\partial ^2 f(x)}{\partial x_n \partial x_2} & \cdots & \frac{\partial ^2 f(x)}{\partial x_n^2} \\ \end{bmatrix}$F(x)$的雅可比矩阵定义为 Jacobi(F)= \begin{bmatrix} \frac{\partial f_1(x)}{\partial x_1} & \frac{\partial f_1(x)}{\partial x_2} & \cdots & \frac{\partial f_1(x)}{\partial x_n} \\ \frac{\partial f_2(x)}{\partial x_1} & \frac{\partial f_2(x)}{\partial x_2} & \cdots & \frac{\partial f_2(x)}{\partial x_n} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial f_m(x)}{\partial x_1} & \frac{\partial f_m(x)}{\partial x_2} & \cdots & \frac{\partial f_m(x)}{\partial x_n} \end{bmatrix}​ 从上述定义中可以看到，$f(x)$的梯度的雅可比矩阵就是其海森矩阵。 凸集 ​ 记$S\in\mathbb R^n$，若对$\forall x_1,\ x_2\in S, \ \forall \lambda \in [0,1]$有 \lambda x_1 + (1-\lambda)x_2 \in S则称$S$是一个凸集。 ​ 感性来说，在一个集合里面任选两点连起来，如果这条线段被这个集合包围，则为凸集，反之就不是，如图1$^{[1]}$。 图1 左：凸集，右：非凸集 凸函数 ​ 对于函数$f(x)$，若满足定义域为非空凸集，且对$\forall x_1,\ x_2\in \mathbf {dom} \ f, \ \forall \lambda \in [0,1]$有 f(\lambda x_1+(1-\lambda) x_2) \le \lambda f(x_1)+(1-\lambda)f(x_2)则称$f(x)$是定义域上的凸函数，$-f(x)$是定义域上的凹函数。 ​ 感性来说，一个函数上任意两点连线，这条线段比原函数不低，则为凸函数，反之则不是，如图2$^{[1]}$。 图2 凸函数 ​ 特别地，如果$f(x)$可微，那么可用更方便的一阶条件（要求一阶可微）、二阶条件（要求二阶可微）判断凸函数。 ​ 一阶条件：定义在非空开凸集上的可微函数$f(x)$是凸函数的充要条件是，对$\forall x_1,\ x_2\in \mathbf {dom} f\ $有 f(x_2) \ge f(x_1)+\nabla f(x_1)^T(x_2-x_1)​ 二阶条件：定义在非空开凸集的二次可微函数$f(x)$是凸函数的充要条件是，对$\forall x \in \mathbf {dom} f\ $有$\nabla ^2 f(x)$半 正定。 凸优化问题 ​ 若一个优化问题是求凸函数在凸集上的极小点，则称为凸优化问题。 ​ 对于引言中所述的优化问题标准形式，若满足$f(x)$是凸函数，$g(x)$是凹函数，$h(x)$是仿射函数，则该优化问题是一个凸优化问题。 ​ 此处要特别注意，优化问题中的约束必须是剔除冗余约束的。举个例子，对于问题 \begin{split} &min\ \ &y\\ &s.t. &y^2-1\ge0\\ &&y\ge0 \end{split}看似$g(y)=y^2-1$的海森矩阵正定，是一个凸函数，故上面这个问题非凸，但实际上从定义出发可推得两个约束构成的可行域是一个凸集，故该问题是一个凸优化问题。之所以产生这样的矛盾是因为上述表达中未剔除冗余约束，把$\{y|y^2-1\ge0\}$改写成$\{y|y\ge1\} \cup \{y|y\le-1\}$，而该集合与另一个约束构成的可行域$\{y|y\ge0\}$的交集为$\{y|y\ge1\}$，即上述问题中$y\le-1$和$y\ge0$均为冗余约束，故原问题等价于 \begin{split} &min\ \ &y\\ &s.t. &y\ge1 \end{split}这显然是一个凸问题，既满足凸问题的原始定义，也符合标准形式判据。 凸优化问题有诸多良好的性质，比如局部最优解就是全局最优解等，通常可以被商业求解器(gurobi、cplex)很好解决，故一个优化问题是不是凸的通常被视为一个问题好不好求解的分水岭。 最优性条件​ 对于一个优化问题，若要找到其最优解，首先就要明确最优解有什么性质，满足什么条件，然后才能够据此去推导求解的算法。最优解满足的条件（必要、充分、充要）称为最优性条件。 ​ 本节仅介绍各种问题的最优性条件，其中的推导与证明可在[1]、[2]中找到。 ​ 在邻域内目标函数值最小的解称为局部最优解（极小点），在整个定义域内目标函数值最小的解称为全局最优解（极小点）。 无约束问题的最优性条件​ 对于可行域是全空间的无约束优化问题 min\ \ f(x)一阶必要条件​ $f(x)$在$\hat x$处可微，若$\hat x$是局部极小点，则$\nabla f(\hat x)=0$。 ​ 这是一个必要条件而非充分条件。一般地，满足$\nabla f(x)=0$的点称为$f(x)$的驻点，如果驻点邻域内的函数值均比驻点函数值大，则该驻点称为极小点；如果驻点领域内函数值均比驻点函数值小，则该驻点称为极大点；两者均不满足则称为鞍点，如图3。 图3 驻点：极小点、极大点与驻点 二阶必要条件​ $f(x)$在$\hat x$处二次可微，若$\hat x$是局部极小点，则$\nabla f(\hat x)=0$，且$\nabla ^2 f(\hat x)$半正定。 ​ 相比一阶必要条件，二阶必要条件多的“海森矩阵“就是用来判断驻点类型的。一般地，对于极大点，海森矩阵半负定；对于极小点，海森矩阵半正定；对于鞍点，海森矩阵不定。 二阶充分条件​ $f(x)$在$\hat x$处二次可微，若$\nabla f(\hat x)=0$，且$\nabla ^2 f(\hat x)$正定，则$\hat x$是局部极小点。 充要条件​ $f(x)$是可微凸函数，则$\hat x$是局部极小点（也是全局最优解）的充要条件是$\nabla f(\hat x)=0$。 ​ 嗯，凸优化问题的良好求解性质可见一斑。 有约束问题的最优性条件​ 对于有约束优化问题（这里不妨都假设$f(x),\ g(x),\ h(x)$均可微） \begin{split} &min\ \ &f(x)\\ &s.t. &g(x)\ge0\\ &&h(x)=0 \end{split}​ 定义广义拉格朗日函数 L(x,\mu,\lambda)=f(x)+\mu ^T g(x)+\lambda ^T h(x)其中$\mu, \ \lambda$称为约束的拉格朗日乘子，其物理意义是约束的右手项（式中为0的那个常数项）变动一个单位对目标函数最优值的影响。 ​ 乘子在很多领域都有直接的应用，在经济学中资源约束的乘子又称为资源的影子价格，在电力市场中有功平衡约束的乘子又称为节点电价。 一阶必要条件（KKT条件）​ 对于上述优化问题，如果$\hat x$是其局部最优解，且$\nabla g(\hat x), \ \nabla h(\hat x)$线性无关，那么必然存在$\hat \mu, \ \hat \lambda$使得 \left \{ \begin{array} \\ & \nabla_xL(\hat x,\ \hat \mu,\ \hat \lambda)=0 &(1) \\ & g(\hat x)\ge0 &(2) \\ & h(\hat x)=0 &(3) \\ & \hat \mu _i g_i(\hat x)=0 &(4) \\ & \hat \mu \ge 0 &(5) \\ \end{array} \right.​ 上式又称为KKT条件，其中： ​ （1）式可以直观地理解为无约束优化问题一阶必要条件的推广，即，将有约束问题的约束通过拉格朗日松弛罚到目标函数中，转成一个无约束问题，再使用无约束优化的一阶必要条件，就是（1）式。 ​ （2）式和（3）式是原问题约束，保证了解的可行性。 ​ （4）式称为互补松弛约束，即每个不等式约束的函数值和其乘子之积择一非零，下标$i$表示约束向量和乘子向量中的各个分量。写成矩阵形式即两个向量正交：$\hat \mu \bot g(\hat x)$。互补松弛约束的物理意义是说，对于每一个不起作用约束（那些函数值大于0而不是等于0的约束）其乘子一定为零。套用影子价格的物理概念，这是很直观的一件事情：如果某项资源在达到最优解时仍有剩余，那么再增加或减少这项资源一个$\epsilon$（无穷小量），并不会引起最优利润的改变，所以影子价格为0，也就是乘子为0。 ​ （5）式是推导过程中的中间条件（用于Gordan定理的应用）。 一阶充分条件​ 特别地，如果该优化问题是一个凸优化问题，那么KKT条件也是“$\hat x$是局部（或全局）最优解”的充分条件。 二阶条件​ 无约束优化的二阶条件也可以推广到有约束优化，即从目标函数的海森矩阵推广到拉格朗日函数的海森矩阵，但会增加一些复杂的规格约束。实际使用中感觉一阶条件更为常用，二阶条件使用较少，在Boyd的书中我也没找到相关论述，感兴趣的同学可以参考陈宝林老师的《最优化》$^{[2]}$中7.2.5节。 对偶问题​ 对偶问题有着强烈的物理意义，在很多算法中都有巧妙的应用，所以在这里也介绍经常用到的一些基本概念。 原问题与对偶问题​ 对于优化问题（称为原问题） \begin{split} & \mathop{min} \limits_x \ &f(x) \\ &s.t. &g(x)\ge0 \\ &&h(x)=0 \\ &&x \in D \end{split}其中集合$D$称为原变量$x$的集约束。集约束可以任意选取，比如选为$\mathbb R ^n$，在比如把$g(x),\ h(x)$全部放进来，均不影响最终求得的对偶问题的一致性，但是会影响计算对偶问题目标函数（又称为拉格朗日对偶函数）的工作量。 ​ 上述原问题对应的对偶问题为 \begin{split} &\mathop{max}\limits_{\mu,\ \lambda} \ &\mathop{inf}\limits_{x \in D} \ L(x,\mu, \lambda) \\ &s.t. &\mu \ge0 \\ \end{split}​ 对偶问题具有互逆性，即对偶问题的对偶问题是原问题。 对偶定理弱对偶定理​ 原问题目标函数值总是大于等于对偶问题目标函数值，即 f(x)\ge\mathop{inf}\limits_{x \in D} \ L(x,\mu, \lambda)\ \ \ \ \ \forall x,\ \mu,\ \lambda​ 原问题目标函数下界与对偶问题目标函数上界之差称为对偶间隙，即$\mathop{inf}\limits_{x}\ f(x)-\mathop{sup}\limits_{\mu,\ \lambda}\ \mathop{inf}\limits_{x \in D} \ L(x,\mu, \lambda)$。 强对偶定理​ 若原问题是一个凸优化问题，且满足slater约束规格，则原问题目标函数下界与对偶问题目标函数上界之差为0，即不存在对偶间隙。 ​ 可见凸优化问题的又一良好求解性质，此时可以通过求对偶问题上界来求原问题最小值，这是在很多算法中经常使用的手段。 鞍点定理 若$\hat x, \ \hat \mu,\ \hat \lambda$满足 L(\hat x,\ \mu,\ \lambda)\le L(\hat x, \ \hat \mu, \ \hat\lambda)\le L(x, \ \hat \mu, \ \hat\lambda)​ 则称$(\hat x, \ \hat \mu, \ \hat\lambda)$是拉格朗日函数的鞍点。 若$(\hat x, \ \hat \mu, \ \hat\lambda)$是拉格朗日函数的鞍点，则$\hat x$和$(\hat \mu,\ \hat \lambda)$分别是原问题和对偶问题的最优解。 若原问题是凸优化问题，且满足slater约束规格，且存在最优解$\hat x$，那么存在$\hat \mu (&gt;0), \ \hat \lambda$使得$(\hat x, \ \hat \mu, \ \hat\lambda)$是拉格朗日函数的鞍点。 参考资料[1] Boyd S, Vandenberghe L. Convex optimization[M]. Cambridge university press, 2004. [2] 陈宝林，最优化理论与算法，清华大学出版社，2005]]></content>
      <categories>
        <category>优化</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[博客编辑与发布]]></title>
    <url>%2F2019%2F07%2F07%2Fblog-edit-deploy%2F</url>
    <content type="text"><![CDATA[markdown规则——怎么写blog标题1个# 到 6个# 分别表示一级标题（large）到六级标题（small)。#号与文字之间留一空 列表无序列表前面加* 1 (* 1) 2 (* 2) 有序列表前面加数字 1 (1. 1) 2 (2. 2) 引用 文字前面加&gt; (&gt; 123) 插入图片 上一行代码为 ! [图片名] (图片地址/链接) 超链接这是GitHub的网站链接。 上一行代码为 这是[GitHub] (http://github.com)的网站链接 粗体与斜体这几个字是粗体，用两个星号包围 这几个字是斜体，用一个星号包围 上一行代码为 **……** *……* 用’\\’进行转义 代码框12import numpy as npimport tensorflow as tf 格式为``` codes ``` 更多规则公式、脚注、删除线、上下标、任务列表、高亮等，点击链接 博客推送规则——怎么传blog 前序工作：github申请一个page，本地安装git、nodes、hexo等，完成个性化设置……详情点击 常用指令： hexo clean：清除部署网站的缓存 hexo g：generate，在本地生成静态网页文件 hexo d：deploy，将本地静态文件部署到github hexo s：sever，将本地静态文件部署到本地端口（localhost:4000） hexo new blogname：新建一个名为blogname的博客 hexo new page pagename：新建一个名为pagename的子网页 blog推送 在hexo安装文件夹处打开git窗口（git bash here）。 hexo命令新建一个博客：hexo new newblog，然后会在hexo文件夹下的/source/_posts文件夹里面生成相应名字的md文件（newblog.md）。 在这个md文件中写入博客内容（markdown格式）。 git窗口中依次输入指令hexo clean清除缓存，输入指令hexo g在本地生成静态文件，输入指令hexo d部署到github中。 完成blog发布。]]></content>
      <categories>
        <category>生产工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F06%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
